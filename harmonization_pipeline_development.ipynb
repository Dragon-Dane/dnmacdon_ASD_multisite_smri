{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmonization Pipeline Development\n",
    "This temporary notebook is being used to develop the python and R pipeline used for harmonizing multisite MRI data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Set up ipywidgets for interactive chart.\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Effect Size Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute effect sizes\n",
    "# Based on method in Nakagawa, S. and I.C. Cuthill. (2007). Biol. Rev. 82. pp. 591-605.\n",
    "\n",
    "import math\n",
    "\n",
    "def cohensd(t, df, n1, n2):\n",
    "    d = ( t * (n1+n2) ) / (math.sqrt(n1*n2) * math.sqrt(df))\n",
    "    se = math.sqrt( ((n1+n2-1)/(n1+n2-3)) * ( (4/(n1+n2)) * (1 + (d**2)/8) ))\n",
    "    return {'d': d, 'se': se, 'lower_ci': d-1.96*se, 'upper_ci': d+1.96*se}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of the data by subset. These are meant to be overlaid, so just show the KDE.\n",
    "def plot_distributions(data, subset_col, display_col):\n",
    "    for sub in data[subset_col].unique():\n",
    "        subset=data[data[subset_col] == sub]\n",
    "        sns.distplot(subset[display_col],hist=False, kde=True, label=sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions, using stacked violin plots, split by the values in y.\n",
    "def plot_stacked_dists(x, y, data, scale = 'count'):\n",
    "    # Plot the distributions of ages across all sites. Extra hue_class column is a hacky solution to get seaborn \n",
    "    # to display half a violin plot.\n",
    "    plt.figure()\n",
    "    sns.set(style = 'whitegrid')\n",
    "    vp_data = pd.DataFrame({'idx': data.index, x: data[x], y: data[y], 'hue_class': 0})\n",
    "    vp_data['hue_class'].loc[-1] = 999\n",
    "    ax_vp = sns.violinplot(y = y, x = x, data = vp_data, hue = 'hue_class', split = True, scale = scale)\n",
    "    ax_vp.legend().remove()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot original and harmonized distributions together, by site.\n",
    "def plot_dual_distributions(x, y, data_unharmonized, data_harmonized, scale = 'count'):\n",
    "    # Plots two distibutions (e.g. harmonized and unharmonized data) as the two halves of stacked violin plots.\n",
    "    plt.figure(figsize = (12,8))\n",
    "    vp_data = pd.DataFrame({x: data_unharmonized[x], y: data_unharmonized[y], 'Legend': 'Unharmonized'})\n",
    "    vp_data = vp_data.append(pd.DataFrame({x: data_harmonized[x], y: data_harmonized[y], 'Legend': 'Harmonized'}))\n",
    "    ax_h_uh = sns.violinplot(y = y, x = x, data = vp_data, hue = 'Legend', split = True, scale = scale)\n",
    "    #ax_h_uh.legend().remove()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a panel of figures useful for quick data exploration and verification.\n",
    "def plot_panel(nucleus, data1, data2):\n",
    "    plt.figure()\n",
    "    fig, axes = plt.subplots(ncols=2, nrows = 2, figsize = (13,4))\n",
    "    plt.subplots_adjust(wspace = 0.5)\n",
    "    \n",
    "    # Plot nucleus volume by Age and TBV: data1\n",
    "    sns.scatterplot('Age', nucleus, data = data1, hue = \"DX\", ax=axes[0,0])\n",
    "    sns.regplot('Age', nucleus, data = data1, scatter = False, ax=axes[0,0])\n",
    "    sns.scatterplot('TBV', nucleus, data = data1, hue = \"DX\", ax=axes[0,1])\n",
    "    sns.regplot('TBV', nucleus, data = data1, scatter = False, ax=axes[0,1])\n",
    "    \n",
    "    # Plot nucleus volume by Age and TBV: data2\n",
    "    sns.scatterplot('Age', nucleus, data = data2, hue = \"DX\", ax=axes[1,0])\n",
    "    sns.regplot('Age', nucleus, data = data2, scatter = False, ax=axes[1,0])\n",
    "    sns.scatterplot('TBV', nucleus, data = data2, hue = \"DX\", ax=axes[1,1])\n",
    "    sns.regplot('TBV', nucleus, data = data2, scatter = False, ax=axes[1,1])\n",
    "    \n",
    "    # Plot the two distributions together\n",
    "    plot_dual_distributions(x=nucleus, y = 'Site', data_unharmonized = data1, data_harmonized = data2, scale = 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot fitted values against residuals\n",
    "# This relies on internal structure of the models. For now, it's the same for the linear regression and linear mixed models.\n",
    "#def plot_fitted_vs_residual(models, ex_data, x_fitted_col, y_resid_col, display_col, hue_col, title_add = None):\n",
    "def plot_fitted_vs_residual(models, ex_data, display_col, hue_col, title_add = None):\n",
    "    plt.figure(figsize = (12,8))\n",
    "    fitted_y = models[display_col].fittedvalues\n",
    "    resid = models[display_col].resid\n",
    "    # The following is not ideal. Need to revisit this solution.\n",
    "    fit_resid_df = pd.DataFrame({'Residual': resid, 'Fitted_Value': fitted_y, 'Site': ex_data['Site'], 'DX': ex_data['DX']})\n",
    "    ax = sns.scatterplot(fitted_y, resid, hue = hue_col, data=fit_resid_df)\n",
    "    ax.set_title('Fitted vs. Residual Plot for ' + display_col + title_add)\n",
    "    ax.set(xlabel = 'Fitted', ylabel = 'Residual')\n",
    "    ax.legend().remove()\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and drop rows with missing values for age, examine structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/data_trimmed_allsites.csv\", index_col=0)\n",
    "#data = pd.read_csv(\"../data/data_trimmed.csv\", index_col=0)\n",
    "\n",
    "# Age is missing in some rows, but is needed for modelling. Drop those rows\n",
    "complete_rows = data['Age'].notna()\n",
    "NA_rows = ~complete_rows\n",
    "data = data[complete_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask features that failed segmentation QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC columns are of the form L_str. Volume data is in L_str_vol\n",
    "QC_cols = ['L_str', 'L_GP', 'L_thal', 'R_str', 'R_GP', 'R_thal']\n",
    "features = [QCc + '_vol' for QCc in QC_cols]\n",
    "\n",
    "QC_failed = data[QC_cols] <= 0.5\n",
    "data[features] = data[features].mask(QC_failed.values)\n",
    "\n",
    "# Write out data with failed structures masked\n",
    "data.to_csv('intermediate_data_masked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L_str_vol</th>\n",
       "      <th>L_GP_vol</th>\n",
       "      <th>L_thal_vol</th>\n",
       "      <th>R_str_vol</th>\n",
       "      <th>R_GP_vol</th>\n",
       "      <th>R_thal_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10423.00</td>\n",
       "      <td>1796.000</td>\n",
       "      <td>6640.00</td>\n",
       "      <td>10586.00</td>\n",
       "      <td>1705.000</td>\n",
       "      <td>6367.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12433.00</td>\n",
       "      <td>1876.000</td>\n",
       "      <td>7987.00</td>\n",
       "      <td>12931.00</td>\n",
       "      <td>1832.000</td>\n",
       "      <td>7428.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2048.000</td>\n",
       "      <td>7742.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1963.000</td>\n",
       "      <td>7335.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1852.000</td>\n",
       "      <td>7983.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1749.000</td>\n",
       "      <td>7430.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9740.00</td>\n",
       "      <td>1580.000</td>\n",
       "      <td>6560.00</td>\n",
       "      <td>10022.00</td>\n",
       "      <td>1504.000</td>\n",
       "      <td>6266.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>7164.21</td>\n",
       "      <td>873.911</td>\n",
       "      <td>4493.81</td>\n",
       "      <td>7198.38</td>\n",
       "      <td>797.289</td>\n",
       "      <td>4117.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>11313.40</td>\n",
       "      <td>1869.000</td>\n",
       "      <td>6693.40</td>\n",
       "      <td>11376.40</td>\n",
       "      <td>1688.400</td>\n",
       "      <td>6287.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>9955.40</td>\n",
       "      <td>1430.800</td>\n",
       "      <td>6997.20</td>\n",
       "      <td>10109.40</td>\n",
       "      <td>1474.200</td>\n",
       "      <td>6631.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1477.200</td>\n",
       "      <td>6357.60</td>\n",
       "      <td>10917.60</td>\n",
       "      <td>1344.000</td>\n",
       "      <td>5863.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>10197.60</td>\n",
       "      <td>1845.200</td>\n",
       "      <td>6841.80</td>\n",
       "      <td>10409.00</td>\n",
       "      <td>1563.800</td>\n",
       "      <td>6196.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>993 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      L_str_vol  L_GP_vol  L_thal_vol  R_str_vol  R_GP_vol  R_thal_vol\n",
       "0      10423.00  1796.000     6640.00   10586.00  1705.000     6367.00\n",
       "1      12433.00  1876.000     7987.00   12931.00  1832.000     7428.00\n",
       "2           NaN  2048.000     7742.00        NaN  1963.000     7335.00\n",
       "3           NaN  1852.000     7983.00        NaN  1749.000     7430.00\n",
       "4       9740.00  1580.000     6560.00   10022.00  1504.000     6266.00\n",
       "...         ...       ...         ...        ...       ...         ...\n",
       "1001    7164.21   873.911     4493.81    7198.38   797.289     4117.94\n",
       "1002   11313.40  1869.000     6693.40   11376.40  1688.400     6287.40\n",
       "1003    9955.40  1430.800     6997.20   10109.40  1474.200     6631.80\n",
       "1004        NaN  1477.200     6357.60   10917.60  1344.000     5863.20\n",
       "1005   10197.60  1845.200     6841.80   10409.00  1563.800     6196.40\n",
       "\n",
       "[993 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[features].mask(QC_failed.values)\n",
    "#QC_failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get harmonized subcortical volume data from neuroCombat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in harmonized features from R output\n",
    "harmonized_features = pd.read_csv(\"harmonized_masked.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Effect of Diagnosis: Linear Models with ComBat Harmonized Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression on ComBat harmonized data\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "models = pd.Series(dtype='object')\n",
    "model_params = pd.Series(dtype = 'object')\n",
    "model_es = []\n",
    "\n",
    "for nucleus in harmonized_features.columns[:-5]:        # Don't include last (covariate) columns\n",
    "    models[nucleus] = ols(formula = nucleus + ' ~ DX + Age + Sex + TBV', data = harmonized_features).fit()\n",
    "#    print(models[nucleus].summary())\n",
    "    model_params[nucleus] = models[nucleus].params\n",
    "\n",
    "    # Get effect size, being sure to drop rows with NA for age.\n",
    "    n_control = sum(data['DX'] == 'Control')\n",
    "    n_ASD = models[nucleus].nobs - n_control\n",
    "    model_es.append(cohensd(t  = models[nucleus].tvalues['DX[T.Control]'], \n",
    "                                df = models[nucleus].df_resid, \n",
    "                                n1 = n_control,\n",
    "                                n2 = n_ASD))\n",
    "\n",
    "combat_es = pd.DataFrame(model_es, index=features)\n",
    "combat_es_filename = \"intermediate_es_combat.csv\"\n",
    "es_filenames = [combat_es_filename]\n",
    "es_names = [\"Combat\"]\n",
    "combat_es.to_csv(combat_es_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Linear Regression on Unharmonized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression on unharmonized data\n",
    "models_unh = pd.Series(dtype='object')\n",
    "model_unh_params = pd.Series(dtype = 'object')\n",
    "model_unh_es = []\n",
    "\n",
    "for nucleus in features:\n",
    "    models_unh[nucleus] = ols(formula = nucleus + ' ~ DX + Age + Sex + TBV + Site', data = data).fit()\n",
    "#    print(models_unh[nucleus].summary())\n",
    "    model_unh_params[nucleus] = models_unh[nucleus].params\n",
    "    \n",
    "    # Get effect size, being sure to drop rows with NA for age.\n",
    "    n_control = sum(data['DX'] == 'Control')\n",
    "    n_ASD = models_unh[nucleus].nobs - n_control\n",
    "    model_unh_es.append(cohensd(t  = models_unh[nucleus].tvalues['DX[T.Control]'], \n",
    "                                    df = models_unh[nucleus].df_resid, \n",
    "                                    n1 = n_control,\n",
    "                                    n2 = n_ASD))\n",
    "\n",
    "unh_es = pd.DataFrame(model_unh_es, index=features)\n",
    "unh_es_filename = \"intermediate_es_unh.csv\"\n",
    "es_filenames.append(unh_es_filename)\n",
    "es_names.append(\"Unharmonized\")\n",
    "unh_es.to_csv(unh_es_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Mixed Model on the Raw Data\n",
    "An alternative analysis is to run a linear mixed model on the raw (unharmonized) data, with site as a random effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code in this cell based on https://www.statsmodels.org/stable/mixed_linear.html\n",
    "# and https://www.statsmodels.org/stable/examples/notebooks/generated/mixed_lm_example.html\n",
    "# import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "lm_models = pd.Series(dtype='object')\n",
    "lm_model_params = pd.Series(dtype = 'object')\n",
    "lm_model_es = []\n",
    "\n",
    "for nucleus in features:\n",
    "    lm_models[nucleus] = smf.mixedlm(nucleus + \" ~ DX + Age + Sex + TBV\", data, groups = data[\"Site\"], missing='drop').fit()\n",
    "    lm_model_params[nucleus] = lm_models[nucleus].params\n",
    "    \n",
    "    # Get effect size, being sure to drop rows with NA for age.\n",
    "    n_control = sum(data['DX'] == 'Control')\n",
    "    n_ASD = lm_models[nucleus].nobs - n_control\n",
    "    lm_model_es.append(cohensd(t  = lm_models[nucleus].tvalues['DX[T.Control]'], \n",
    "                          df = lm_models[nucleus].df_resid, \n",
    "                          n1 = n_control,\n",
    "                          n2 = n_ASD))\n",
    "    \n",
    "lmm_es = pd.DataFrame(lm_model_es, index=features)\n",
    "lmm_es_filename = \"intermediate_es_lmm.csv\"\n",
    "es_filenames.append(lmm_es_filename)\n",
    "es_names.append(\"Mixed_model\")\n",
    "lmm_es.to_csv(lmm_es_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Effect Sizes and Export for Forest Plot in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out files containing output file names and type of data\n",
    "pd.DataFrame(es_filenames).to_csv(\"es_filenames.csv\", index=False, header=False)\n",
    "pd.DataFrame(es_names).to_csv(\"es_names.csv\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    " 1. Add references section\n",
    " 2. Look up (Ross's? Greg's?) documentation strings and document functions\n",
    " 3. Deal with missing values, and remove values based on QC.\n",
    " 4. Make the code more \"Pythonic\" - there are places where I'm not using dataframes and series in quite the optimal way.\n",
    " 5. Add meta-analysis code for another option - it's another ENIGMA technique, with mature packages available in R, but not in Python.\n",
    " 6. Create an interactive figure that shows the effect of adding or removing terms from the model. Noticed some significant clustering in the residual vs. fitted plots by DX when TBV was taken out of the model. When added back in, the clustering disappeared. This was particularly evident in the thalamus.\n",
    " 7. Check structures against TBV, and DX against TBV. The clustering in the thalamus (see above) was quite noticeable, and disappears when TBV is included in the model. Note that p values for DX move from ~ .05 to > .5 when TBV is included in the model. This suggests that any volumetric effect in the subcortical structures is largely driven by differences in TBV.\n",
    " * Consider, should I be harmonizing TBV as well?\n",
    " 8. Plot the effect sizes and SEs.\n",
    " 9. Open data, and package up with a full data file.\n",
    " 10. Deal with collinearity in models, e.g. nucleus volume and TBV.\n",
    "\n",
    "## In the future\n",
    " 1. Have a look at metafor - can I reproduce some of it in a Python package? That would be a cool way to make a contribution. Could do it piecemeal. Discuss with Gabe.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:harmonization] *",
   "language": "python",
   "name": "conda-env-harmonization-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
